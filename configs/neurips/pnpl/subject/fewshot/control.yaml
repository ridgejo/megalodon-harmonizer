experiment:
  seed: 42
  epochs: 5

finetune:
  freeze_all: false
  voiced_classifier:
    type: "mlp"
    input_dim: 2560
    hidden_dim: 512

rep_config:
  lr: 0.000066
  dataset_block:
    dataset_sizes:
      armeni2022: 269
      schoffelen2019: 273
      gwilliams2022: 208
    shared_dim: 512
    use_data_block: true
  encoder:
    channels: 512
    conv_channels: [512, 512, 512, 512]
    ratios: [5, 5, 1]
    dimension: 512
  projector:
    input_dim: 2560
    hidden_dim: 2048
  band_predictor:
    input_dim: 2560 # 300 * 5 = 1500
  amp_scale_predictor:
    input_dim: 2560 # 300 * 5 = 1500
    prop: 0.2
  phase_diff_predictor:
    input_dim: 2560 # 300 * 5 = 1500
    prop: 0.5

datamodule_config:
  dataset_preproc_configs:
    gwilliams2022:
      data_path: "/data/engs-pnpl/lina4368/gwilliams2022"
      preproc_path: "/data/engs-pnpl/lina4368/gwilliams2022"
      l_freq: 0.5
      h_freq: 125
      resample_freq: 250
      notch_freq: 50
      interpolate_bad_channels: true
      window_len: 0.5
      info: ["subject", "subject_id", "dataset"]
      include_subjects: ["08", "09", "10"]
      preload: true
      label: "voicing"
      label_delay: 0.02
  dataloader_configs:
    train_ratio: 0.6
    val_ratio: 0.1
    test_ratio: 0.3
    pred_ratio: 0.0
    batch_size: 128
    normalisation:
      n_sample_batches: 8
      per_channel: true
      scaler_conf:
        standard_scaler:
