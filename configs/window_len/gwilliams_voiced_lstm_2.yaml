experiment:
  seed: 42

rep_config:
  lr: 0.000630957344480193
  dataset_block:
    dataset_sizes:
      armeni2022: 269
      schoffelen2019: 273
      gwilliams2022: 208
    shared_dim: 300
    use_data_block: true
  encoder:
    channels: 300
    conv_channels: [256, 512, 768]
    ratios: [4, 2] # 300 // 2 = 150, // 2 = 75?
    dimension: 300
  subject_embedding:
    dataset_keys: ["gwilliams2022"]
    embedding_dim: 16
  voiced_classifier:
    type: "lstm"
    input_dim: 300
    hidden_dim: 512
    num_layers: 2

datamodule_config:
  dataset_preproc_configs:
    gwilliams2022:
      bad_subjects: []
      slice_len: 2.0
      label_type: "voiced"
  dataloader_configs:
    train_ratio: 0.9
    val_ratio: 0.04
    test_ratio: 0.04
    pred_ratio: 0.02
    batch_size: 128
    normalisation:
      n_sample_batches: 8
      per_channel: true
      scaler_conf:
        standard_scaler: