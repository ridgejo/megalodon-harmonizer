experiment:
  seed: 42

rep_config:
  lr: 0.001
  dataset_block:
    dataset_sizes:
      armeni2022: 269
      schoffelen2019: 273
      gwilliams2022: 208
    shared_dim: 300
    use_data_block: true
  encoder:
    channels: 300
    conv_channels: [512, 512]
    ratios: [1]
    dimension: 300
  vad_classifier:
    input_dim: 300
    hidden_dim: 512

datamodule_config:
  dataset_preproc_configs:
    gwilliams2022:
      bad_subjects: []
      slice_len: 3.0
      label_type: "vad"
  dataloader_configs:
    train_ratio: 0.9
    val_ratio: 0.04
    test_ratio: 0.04
    pred_ratio: 0.02
    batch_size: 8 # Use batch_size = 8 (72% memory) for standard 24GiB GPU
    normalisation:
      n_sample_batches: 8
      per_channel: true
      scaler_conf:
        standard_scaler: